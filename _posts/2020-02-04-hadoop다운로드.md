---
title : "Apache Hadoop 설치하기"
author : "금주"
#categories : - Project
date: "2020-02-04"
---

# Hadoop 의 구축 방법
---
* 단독 작업 모드 (Stand-Alone Operation)
* 가상 분산 모드 (Pseudo-Distributed Operation)
* 완전 분산 모드 (Fully-Distributed Operation)

나는 가상 분산모드 할거임


~ 순서 ~

1. 하둡 설치하기
2. 하둡 서버 구축
3. 하둡 스파크 연동

# 하둡(Hadoop) 설치하기
---



{% raw %} <img src="https://bcloved.github.io/assets/images/20200204ApacheHadoop/1.PNG" alt=""> {% endraw %}

영상에서는 위의 사진과 같은  3대의 가상머신을 만들었다.
네임노드 : 파일을 쪼개고 쪼개진 파일이 어떤 데이터 노드에 저장되어져 있는지 기억하는 컴퓨터
데이터 노드 : 실제 사용자가 업로드한 데이터를 쪼개진 형태로 보관하고 있는 컴퓨터



파일의 이름이나 경로는 네임노드에 저장되고 , 실제 데이터는 데이터 노드에 분산되어 저장되어져 있음

하둡은 자바로 개발이 되었기 때문에 java가 가장 접근성이 좋지만 php, python 으로도 제어할 수 있다.

하둡은 큰 데이터를 처리하기 위해 만들어 졌기 때문에 작은파일도 병렬처리로 처리를 하기 때문에 시간이 오래걸린다.


나는 가상머신 2개를 이용해서 분산 컴퓨팅 환경을 구축하려고 한다.
데이터가 많이 필요하지 않을 것 같아 2개만 사용할 예정 ( master-slave )

아 그리고 가상머신은 virtual box 를 사용할 것이다.

## 서버 환경 구성하기

1. user / usergroup 생성

모든 서버에 haoop 그룹과 유저를 생성하고 권한을 부여해 준다.


> sudo addgroup hadoop <br>
sudo adduser --ingroup hadoop hduser



{% raw %} <img src="https://bcloved.github.io/assets/images/20200204ApacheHadoop/2.PNG" alt=""> {% endraw %}

> sudo visudo

{% raw %} <img src="https://bcloved.github.io/assets/images/20200204ApacheHadoop/3.PNG" alt=""> {% endraw %}

sudoers file 에 hduser 을 추가한다.

> su -hduser

{% raw %} <img src="https://bcloved.github.io/assets/images/20200204ApacheHadoop/4.PNG" alt=""> {% endraw %}

hduser 로 로그인을 한다.

2. ssh 설정

hadoop 은 분산 처리시에 서버들간의 ssh 통신을 자동으로 수행하기 때문에 이를 암호없이 접속할 수 있도록 master 서버에서 공개키를 생성하고 생성된 키를 각 서버들에 배표해준다.


>sudo -s

관리자 권환 획득

> vi /etc/ssh/sshd_confing

sshd 파일을 수정




3. java 설치




4. locale 확인 (옵션)



---
참고
<https://daeson.tistory.com/277?category=679387>
<https://bisn.tistory.com/9>
